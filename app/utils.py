import torch  # ThÃªm dÃ²ng nÃ y Ä‘á»ƒ import thÆ° viá»‡n torch
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification

# ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh vÃ  tokenizer
TOKENIZER_PATH = 'app/model/bert_tokenizer'
MODEL_PATH = 'app/model/sentiment_model'

def load_model():
    # Táº£i tokenizer vÃ  model tá»« cÃ¡c thÆ° má»¥c lÆ°u mÃ´ hÃ¬nh
    tokenizer = DistilBertTokenizerFast.from_pretrained(TOKENIZER_PATH)
    model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)
    return tokenizer, model

# HÃ m phÃ¢n tÃ­ch cáº£m xÃºc
def predict_sentiment(text, tokenizer, model, device):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=1).item()
    label_map = {0: "Negative ğŸ˜ ", 1: "Neutral ğŸ˜", 2: "Positive ğŸ˜Š"}
    return label_map[predicted_class]
